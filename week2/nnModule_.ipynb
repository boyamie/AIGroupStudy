{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKMgLgTdcn9nWkVHBFguy1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EKYdMUbi-uJ",
        "outputId": "dbfbb4ec-8006-42b6-ff51-8982ed5b40fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 4848.02685546875\n",
            "199 3418.248291015625\n",
            "299 2411.562744140625\n",
            "399 1702.5494384765625\n",
            "499 1203.041748046875\n",
            "599 851.036865234375\n",
            "699 602.9140625\n",
            "799 427.973876953125\n",
            "899 304.6033935546875\n",
            "999 217.58135986328125\n",
            "1099 156.18618774414062\n",
            "1199 112.86293029785156\n",
            "1299 82.28650665283203\n",
            "1399 60.702903747558594\n",
            "1499 45.464759826660156\n",
            "1599 34.70500183105469\n",
            "1699 27.10641098022461\n",
            "1799 21.739526748657227\n",
            "1899 17.94843292236328\n",
            "1999 15.270158767700195\n",
            "Result: y = 0.08419925719499588 + 0.8676232099533081 x + -0.014525770209729671 x^2 + -0.09487830847501755 x^3\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "PyTorch의 특징\n",
        "1. NumPy와 유사하지만 GPU 상에서 실행 가능한 n-차원 텐서(Tensor)\n",
        "2. 신경망을 구성하고 학습하는 과정에서의 자동 미분(Automatic differentiation)\n",
        "\"\"\"\n",
        "import torch\n",
        "import math\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# 무작위로 입력과 출력 데이터를 생성\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# 무작위로 가중치 초기화\n",
        "a = torch.randn((), device=device, dtype=dtype)\n",
        "b = torch.randn((), device=device, dtype=dtype)\n",
        "c = torch.randn((), device=device, dtype=dtype)\n",
        "d = torch.randn((), device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "    # 순전파: 예측값 y 계산\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # loss compute\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # 손실에 따른 a, b, c, d gradient compute & backpropagation\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # 가중치 갱신\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "dtype = torch.float\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.set_default_device(device)\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "a = torch.randn((), dtype=dtype, requires_grad=True)\n",
        "b = torch.randn((), dtype=dtype, requires_grad=True)\n",
        "c = torch.randn((), dtype=dtype, requires_grad=True)\n",
        "d = torch.randn((), dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        a -= learning_rate * a.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        c -= learning_rate * c.grad\n",
        "        d -= learning_rate * d.grad\n",
        "\n",
        "        a.grad = None\n",
        "        b.grad = None\n",
        "        c.grad = None\n",
        "        d.grad = None\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3b0IPqBjHoQ",
        "outputId": "75b72ea1-9f16-4015-89a9-00f6dd5b1b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 5619.09130859375\n",
            "199 3725.643798828125\n",
            "299 2471.54443359375\n",
            "399 1640.81689453125\n",
            "499 1090.4683837890625\n",
            "599 725.8222045898438\n",
            "699 484.18438720703125\n",
            "799 324.03656005859375\n",
            "899 217.8807830810547\n",
            "999 147.5024871826172\n",
            "1099 100.83580017089844\n",
            "1199 69.8859634399414\n",
            "1299 49.35568618774414\n",
            "1399 35.734134674072266\n",
            "1499 26.694459915161133\n",
            "1599 20.69403839111328\n",
            "1699 16.710033416748047\n",
            "1799 14.064082145690918\n",
            "1899 12.306336402893066\n",
            "1999 11.13830852508545\n",
            "Result: y = -0.015421641059219837 + 0.8121002912521362 x + 0.0026604891754686832 x^2 + -0.0869806557893753 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class LegendrePolynomial3(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    torch.autograd.Function을 상속받아 사용자 정의 autograd Function을 구현하고,\n",
        "    텐서 연산을 하는 순전파 단계와 역전파 단계를 구현해보겠습니다.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        순전파 단계에서는 입력을 갖는 텐서를 받아 출력을 갖는 텐서를 반환합니다.\n",
        "        ctx는 컨텍스트 객체(context object)로 역전파 연산을 위한 정보 저장에 사용합니다.\n",
        "        ctx.save_for_backward 메소드를 사용하여 역전파 단계에서 사용할 어떤 객체도\n",
        "        저장(cache)해 둘 수 있습니다.\n",
        "        \"\"\"\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        역전파 단계에서는 출력에 대한 손실(loss)의 변화도(gradient)를 갖는 텐서를 받고,\n",
        "        입력에 대한 손실의 변화도를 계산해야 합니다.\n",
        "        \"\"\"\n",
        "        input, = ctx.saved_tensors\n",
        "        return grad_output * 1.5 * (5 * input ** 2 - 1)\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 5e-6\n",
        "for t in range(2000):\n",
        "    P3 = LegendrePolynomial3.apply\n",
        "\n",
        "    y_pred = a + b * P3(c + d * x)\n",
        "\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        a -= learning_rate * a.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        c -= learning_rate * c.grad\n",
        "        d -= learning_rate * d.grad\n",
        "\n",
        "        a.grad = None\n",
        "        b.grad = None\n",
        "        c.grad = None\n",
        "        d.grad = None\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO4VPyRsjbDx",
        "outputId": "0cd1048f-ca95-4103-bfcd-3b3a1b70baa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 209.95834350585938\n",
            "199 144.66018676757812\n",
            "299 100.70249938964844\n",
            "399 71.03519439697266\n",
            "499 50.978511810302734\n",
            "599 37.403133392333984\n",
            "699 28.206867218017578\n",
            "799 21.97318458557129\n",
            "899 17.7457275390625\n",
            "999 14.877889633178711\n",
            "1099 12.93176555633545\n",
            "1199 11.610918045043945\n",
            "1299 10.71425724029541\n",
            "1399 10.10548210144043\n",
            "1499 9.692105293273926\n",
            "1599 9.411375999450684\n",
            "1699 9.220745086669922\n",
            "1799 9.091285705566406\n",
            "1899 9.003361701965332\n",
            "1999 8.943641662597656\n",
            "Result: y = -6.71270206087371e-10 + -2.208526849746704 * P3(-3.392665037793563e-10 + 0.2554861009120941 x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")\n",
        "\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(2000):\n",
        "\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n",
        "\n",
        "linear_layer = model[0]\n",
        "\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opUc2KpYjiJ6",
        "outputId": "63342284-fa2a-45ff-e12e-1d3b54729015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 947.629150390625\n",
            "199 630.5597534179688\n",
            "299 420.619140625\n",
            "399 281.5987548828125\n",
            "499 189.5318145751953\n",
            "599 128.5537109375\n",
            "699 88.16189575195312\n",
            "799 61.403594970703125\n",
            "899 43.6746711730957\n",
            "999 31.926652908325195\n",
            "1099 24.14076805114746\n",
            "1199 18.979907989501953\n",
            "1299 15.558510780334473\n",
            "1399 13.289920806884766\n",
            "1499 11.785417556762695\n",
            "1599 10.787452697753906\n",
            "1699 10.125357627868652\n",
            "1799 9.685970306396484\n",
            "1899 9.394330978393555\n",
            "1999 9.200701713562012\n",
            "Result: y = 0.00567869795486331 + 0.838431715965271 x + -0.0009796705562621355 x^2 + -0.09072607755661011 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "p = torch.tensor([1, 2, 3])\n",
        "xx = x.unsqueeze(-1).pow(p)\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(3, 1),\n",
        "    torch.nn.Flatten(0, 1)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-3\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "for t in range(2000):\n",
        "    y_pred = model(xx)\n",
        "\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "linear_layer = model[0]\n",
        "print(f'Result: y = {linear_layer.bias.item()} + {linear_layer.weight[:, 0].item()} x + {linear_layer.weight[:, 1].item()} x^2 + {linear_layer.weight[:, 2].item()} x^3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xqe5MLJWkw0_",
        "outputId": "12f25bb9-3a4a-4618-a48e-661dc4950d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 2345.16748046875\n",
            "199 1292.9144287109375\n",
            "299 833.9534912109375\n",
            "399 557.508056640625\n",
            "499 365.7161865234375\n",
            "599 233.73605346679688\n",
            "699 143.05813598632812\n",
            "799 82.76093292236328\n",
            "899 45.35905456542969\n",
            "999 24.201065063476562\n",
            "1099 13.694792747497559\n",
            "1199 9.757513046264648\n",
            "1299 8.985492706298828\n",
            "1399 8.946434020996094\n",
            "1499 8.913481712341309\n",
            "1599 8.89508056640625\n",
            "1699 8.950029373168945\n",
            "1799 8.943550109863281\n",
            "1899 8.918205261230469\n",
            "1999 8.913856506347656\n",
            "Result: y = -0.00036965752951800823 + 0.8572367429733276 x + -0.00038993870839476585 x^2 + -0.09283436089754105 x^3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        생성자에서 5개의 매개변수를 생성(instantiate)하고 멤버 변수로 지정합니다.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.a = torch.nn.Parameter(torch.randn(()))\n",
        "        self.b = torch.nn.Parameter(torch.randn(()))\n",
        "        self.c = torch.nn.Parameter(torch.randn(()))\n",
        "        self.d = torch.nn.Parameter(torch.randn(()))\n",
        "        self.e = torch.nn.Parameter(torch.randn(()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        모델의 순전파 단계에서는 무작위로 4, 5 중 하나를 선택한 뒤 매개변수 e를 재사용하여\n",
        "        이 차수들의의 기여도(contribution)를 계산합니다.\n",
        "\n",
        "        각 순전파 단계는 동적 연산 그래프를 구성하기 때문에, 모델의 순전파 단계를 정의할 때\n",
        "        반복문이나 조건문과 같은 일반적인 Python 제어-흐름 연산자를 사용할 수 있습니다.\n",
        "\n",
        "        여기에서 연산 그래프를 정의할 때 동일한 매개변수를 여러번 사용하는 것이 완벽히 안전하다는\n",
        "        것을 알 수 있습니다.\n",
        "        \"\"\"\n",
        "        y = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "        for exp in range(4, random.randint(4, 6)):\n",
        "            y = y + self.e * x ** exp\n",
        "        return y\n",
        "\n",
        "    def string(self):\n",
        "        \"\"\"\n",
        "        Python의 다른 클래스(class)처럼, PyTorch 모듈을 사용해서 사용자 정의 메소드를 정의할 수 있습니다.\n",
        "        \"\"\"\n",
        "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3 + {self.e.item()} x^4 ? + {self.e.item()} x^5 ?'\n",
        "\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "model = DynamicNet()\n",
        "\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
        "for t in range(30000):\n",
        "    y_pred = model(x)\n",
        "\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 2000 == 1999:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f'Result: {model.string()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XfDEfpzl0wX",
        "outputId": "a0ecdae0-5c48-4d33-8b3a-8027422a551b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1999 369.0102233886719\n",
            "3999 171.28018188476562\n",
            "5999 80.9932632446289\n",
            "7999 36.49665069580078\n",
            "9999 21.01321029663086\n",
            "11999 14.379067420959473\n",
            "13999 10.882006645202637\n",
            "15999 10.124473571777344\n",
            "17999 8.892494201660156\n",
            "19999 9.127750396728516\n",
            "21999 9.008630752563477\n",
            "23999 8.910588264465332\n",
            "25999 8.889765739440918\n",
            "27999 8.612383842468262\n",
            "29999 8.864383697509766\n",
            "Result: y = 0.0003653020248748362 + 0.859559178352356 x + -0.0006391971837729216 x^2 + -0.09403101354837418 x^3 + 0.0001303298631682992 x^4 ? + 0.0001303298631682992 x^5 ?\n"
          ]
        }
      ]
    }
  ]
}
